\chapter{Design and Implementation}\label{implement}

    In this chapter, the implementation details will be explained in many aspects, including Java Native Interface,
    human detection, and distance calculation.

    \section{Preparation}
        This application is implemented on the Android Operating System,
        and the target Software Development Kit (SDK) version is set at level 29, namely Android Q.
        This application is compiled and built by Android Studio version 3.5.3,
        and CMake is used for compiling C++ library with C++ version 11.
        Furthermore, OpenCV version 4.4.0, which is built as shared library, is used for image processing and object detection.
        For object detection model, there are 2 models are used: You Only Look Once and MobileNet SSD.

    \section{Java Native Interface}
        Implementation is divided into 3 layers.
            The first layer is an application layer, which is written in Java.
                This Layer mainly interacts with a user, checks permissions, and communicates with Java Native Interface (JNI).
                In addition, this layer also handle I/O implementation such as camera, file, and storage.
            The second layer is JNI, which is written in C and C++.
                JNI layer performs 2 main tasks.
                    The fist task is being an intermediate connection between the application layer and a library layer.
                    The second task is loading native shared libraries, which is compiled by a Native Development Kit (NDK).
            The last layer is the library layer, which is written in C++.
                This layer performs calculation tasks, including Deep Neural Network and distance calculation.

        However, Deep Neural Network and distance calculation can be implemented in the application layer,
        According to Android Developer Guide \cite{ANDROID-01},
        Native Development Kit (NDK) is recommended for compiling C and C++ coode into native library,
        which is able to achieve a higher performance.
        Thus, executing both tasks in the library layer gains a better performance.
        Furthermore, there are 2 advantages of implementing JNI.
            The first advantage is reducing JNI calling. Performing both tasks in an application layer have to call JNI methods many times,
                and this is expensive and cost an overhead.
                Thus, implementing JNI manually reduces the number of JNI calls.
            The second advantage is memory management. C++ is able to access values in the memory by using a pointer.
                Thus, values can be directly accessed without copying.

    \section{Social Distancing Detection}
        % Intro to detection
        There are 3 main processes is implemented to determine social distancing violation from the image and video.

        The first process is pre-processing the given image, video, or video stram.
        The given video will be extracted into an array of images.
        Then, images will be converted into Bitmap and Mat format with RGBA colour model respectively.
        After that, colour will be converted, which depends on a detection model.
        As mentioned in section 4.1, there are 2 detection models are used for detecting humans in the given picture and video: YOLO model and MobileNet SSD model.
        Colour will be converted to RGB if the detection model is YOLO,
        while MobileNet SSD requires BGR colour model.

        \begin{figure}[!ht]
            \centering
            \includegraphics[width=5in]{images/chapter3/system-overview.png}
            \caption{Detection System Overview}
            \label{systemOverview}
        \end{figure}

        The second process is object detection.
        Detection models are setup and configured differently before processing images.
        First of all, YOLO is used with Darknet, which is an open source neural network framework,
            while MobileNet SSD. MobileNet is used with Caffe framework.
        Then, threshold will be set for determining the confidence level of the detected object.
            The confidence level threshold of YOLO model will be set to 0.5 or 50 percent.
            In other words, the detected object will be rejected if YOLO model cannot guarantee that a detected object is human,
            and its confidence level is lower than 50 percent.
            In contrast, The confidence level threshold of MobileNet SSD model will be set to 0.3 or 30 percent.
            Because of MobileNet SSD model has a lower ability to detect an object, the confidence threshold is set to be lower.
        After models are setup and configured, the image will be processed in 5 steps.
        For the first step, pre-processed image will be convert to input blob by passing Mat image to $blobFromImage()$ function with scale factor.
            Blob will be used for the forward propagation in the neural network.
        Secondly, blob will be passed to the network through $forward()$ function,
            and the network's output is a list of detected boxes with a label and a confidence level.
        Then, detected objects will be classified.
            Non-human objects will be removed by considering the label of the detected object.
        After that, a confidence level will be filtered by considering the threshold that is set in the configuration step.
        Finally, $NMSBoxes()$ performs non-maximum suppression, which will reduce overlapping detected boxes.

        The last process is determining social distancing.
        After a list of detected object boxes is filtered,
        the distance between each box will be calculated by using the formula which is based on Euclidean distance
        \footnote{an explanation was given in chapter \ref{background}}.
        If the value of the calculated distance is lower than the threshold,
        this mean that the couple is too close, and they are breaking social distancing rule.
        The application will change the box's colour to red.
        In contrast, if the value of the calculation is grater than threshold,
        there is no breaching of social distancing rule, and the box's colour will be changed to green.

    \section{Parallelisation}
        -	Intro about parallelisation – How it works in Android
            - Thread vs ThreadPool
            - Handler
        -	Multithreading and Multicore
        -	System overview (Manager – Task – Runnable)
            - <Insert diagram>
        -	1 frame per 1 thread
            - <Insert diagram>
            \begin{lstlisting}
                for i:=maxint to 0 do
                begin
                { do nothing }
                end;
                Write('Case insensitive ');
                Write('Pascal keywords.');
            \end{lstlisting}

        \subsection{Multitheading with Java}

            \begin{figure}[!ht]
                \includegraphics[width=6in]{images/chapter3/parallel.png}
                \caption{Parallel Computing Diagram}
                \label{systemOverview}
            \end{figure}
            -	How to implement
                - Using Java
                - Thread pool
                    <insert sample of code>
            -	Memory Management
                - Singleton Pattern
                - Static block
                    - Executed only once
                - Queue and recycling

        \subsection{Multitheading with C++}

        - How to show processed frame from live stream?
