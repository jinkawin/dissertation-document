\chapter{Background}\label{background}

    This chapter aims to introduce background knowledge that relates to this project.
    Then, this chapter gives examples of related applications.

    \section{Threading in Android}
        Threads in Android development are categorised into two main categories: the main thread and a worker thread.
        A main thread or UI thread is a thread that dispatch events of user interface widgets.
        The events are dispatched regarding Android's activity lifecycle,
        and all events are managed by only one thread.
        In other words, threads will not be spawned for handling a single event or component.
        Thus, if there is a long-running task, which is run by UI thread, events cannot be delivered
        because long-running task block UI thread.
        If UI thread is blocked more than 5 seconds,
        an application will show "Application not Responding"  \cite{ANDROID-01}.

        \begin{figure}[!ht]
            \centering
            \includegraphics[width=3in]{images/chapter2/thread-overview.png}
            \caption{Threading Overview}
            \label{thread-overview}
        \end{figure}

        A working thread is separated from the UI thread to avoid freezing application,
            and it is called worker thread or background thread.
            This thread is able to process a long-running task in the background without interrupting the UI thread.
        In addition, the priority of the thread can be set from -20 to 19---the lowest priority is 19 and the highest priority is -20.
            The default value of background threads priority is 10,
            and the default value of foreground threads is -2.

        UI thread and background thread are running on different threads;
        thus, Handler is needed when there is communication between these threads.
        For example, as shown in figure \ref{thread-overview},
        processes are divided into two parts: foreground and background.
        Tasks are created by a manager which is running on the UI thread.
        Then, Runnable, a component that can be run by background threads, will read tasked.
        After that, Runnable will be executed by background threads.
        Finally, Runnable will notify the manager through Handler.

    \section{Distance Calculation}\label{sectionDistanceCalculation}
        According to Gurucharan \cite{SOCIAL-DISTANCING-DETECTION}, to measure a distance between 2 people, the reference point of people are used for calculation.
        The reference point is the coordination of each people, which is the centre of the detection frame.
        The calculation formula is based on Euclidean distance.

        \begin{equation*}
            d = \sqrt{(a_{0}-b_{0})^{2}+(D/c)\times(a_{1}-b_{1})^{2}}
        \end{equation*}

        \begin{equation*}
            c = \frac{a_{1}+b_{1}}{2}
        \end{equation*}

        However, three-dimensional space are captured into a two-dimensional image,
        so depth and perspective are concerned as can be seen in figure \ref{distanceCalculation}.
        Thus, a couple of variables are added into the formula.
        The first variable is $D$, which is the diagonal of the image.
        The second variable is $c$, which is a calibration.
        These two variables will determine the depth of people in the image.

        \begin{figure}[h!]
            \centering
            \begin{subfigure}{.5\textwidth}
              \centering
              \includegraphics[width=2.5in]{images/chapter2/distance.png}
              \caption{Distance calculation}
              \label{distanceCalculation}
            \end{subfigure}%
            \begin{subfigure}{.5\textwidth}
              \centering
              \includegraphics[width=2.5in]{images/chapter2/two-distances.png}
              \caption{A difference of 2 distances}
              \label{twoDistances}
            \end{subfigure}
            \caption{Determining Social Distancing}
            \label{determiningConcept}
        \end{figure}

        For example, according to figure \ref{twoDistances},
        if the distance is calculated without calibration, the distance between 2 couples will be the same.
        Naturally, the distance between Human1 and Human2 must be further than the distance between Human3 and Human4.

    \section{Specification}
        This application is developed and tested on following specification:

        \begin{table}[!htp]\centering
            \scriptsize
            \begin{tabular}{lrll}\toprule
                Device              &Device             &Samsung S10+ \\ \hline
                Operating System    &Operating System   &Android 10 (Q) \\ \hline
                Processor           &CPU                &Samsung Exynos 9820 \\
                                    &Cores              &8 \\
                                    &Architecture       &2x ARM Cortex-A75 2.73GHz \\
                                    &                   &4x ARM Cortex-A55 1.95GHz \\
                                    &                   &2x Samsung Exynos M4 1.95 GHz \\
                                    &GPU                &Mali-G76 \\ \hline
                Memory              &RAM                &8 GB \\
                \bottomrule
            \end{tabular}

            \caption{Specification}\label{specification}
        \end{table}


    \section{Existing Applications}
        \subsection{Object Detector}
            Object Detector is an Android application, which is able to detect objects through a camera.
            This application is implemented by deep learning library from TensorFlow with
            MobileNet model. There are two modes in this application,
            which are detection mode and classification mode.
            The processing time of each frame is 250 to 300 milliseconds.

        \subsection{TensorFlow Object Detection}
            TensorFlow Object Detection is an object detection application,
            which is run on the Android operating system.
            TensorFlow's library is used in this application, along with the MobileNet model.
            This application is able to detect objects in real-time from the camera.


        \subsection{Computer Vision Detection}
            Computer Vision Detection application operates on the Android operating system.
            This application is able to process real-time video from a live camera,
            and OpenCV is used as a library.
            There are 12 options of algorithms, such as colour detector, canny detector, motion detector, and shape detector.
            Besides, this application is able to detect human faces and smiling faces.
            This application is able to process around 13 frames per second.
